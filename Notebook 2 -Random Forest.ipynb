{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f434c-8728-477b-a86c-a34ab3dd5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "# display options\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 200)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Imports ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafeb91-ad4f-4f32-b8fb-399da1a2c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: load and view CSV  \n",
    "df = pd.read_csv('survey.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(6))\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa801474-b7f4-4208-9fdd-a1121dbcaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Exploratory Data Analysis\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"\\nTarget value counts (treatment):\")\n",
    "print(df['treatment'].value_counts(dropna=False))\n",
    "\n",
    "# Missing values %\n",
    "missing_pct = df.isna().mean().sort_values(ascending=False) * 100\n",
    "display(missing_pct[missing_pct>0].round(2))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=df, x='treatment', order=df['treatment'].value_counts().index)\n",
    "plt.title('Distribution of target: treatment')\n",
    "plt.show()\n",
    "\n",
    "# Age\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "# Outliers removal\n",
    "df2 = df[(df['Age'] >= 14) & (df['Age'] <= 100)].copy()\n",
    "\n",
    "# New DataFrame to plot\n",
    "sns.histplot(df2['Age'].dropna(), bins=30)\n",
    "plt.title('Age distribution (Filtered 0-100 years)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5899d36-9308-4a73-a06b-a56c1e2e761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Final Data Preparation Pipeline\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Gender Cleaning Function\n",
    "# Standardizes messy gender labels into: \"Male\", \"Female\", or \"Other\"\n",
    "def clean_gender(x):\n",
    "    if pd.isna(x):\n",
    "        return 'Other'\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    # Map all variations to \"Male\"\n",
    "    if s in ['male', 'm', 'man', 'male-ish', 'maile', 'mal', 'cis male', 'male (cis)']:\n",
    "        return 'Male'\n",
    "\n",
    "    # Map all variations to \"Female\"\n",
    "    if s in ['female', 'f', 'woman', 'female (cis)', 'cis female']:\n",
    "        return 'Female'\n",
    "\n",
    "    # Everything else becomes \"Other\"\n",
    "    return 'Other'\n",
    "\n",
    "\n",
    "# Create df3 and Apply Cleaning Steps\n",
    "df3 = df2.copy()\n",
    "\n",
    "# Clean gender column\n",
    "df3['Gender_clean'] = df3['Gender'].apply(clean_gender)\n",
    "\n",
    "# Convert Yes/No columns to binary 1/0\n",
    "bin_cols = [\n",
    "    'self_employed', 'family_history', 'treatment', 'remote_work', 'tech_company',\n",
    "    'benefits', 'care_options', 'wellness_program', 'seek_help', 'anonymity'\n",
    "]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "    for c in bin_cols:\n",
    "        if c in df3.columns:\n",
    "            series = df3[c].replace({'Yes': 1, 'No': 0})\n",
    "            df3.loc[:, c] = pd.to_numeric(series, errors='coerce')\n",
    "\n",
    "print(\"df3 cleaned (gender and binary columns).\")\n",
    "\n",
    "\n",
    "# Select Candidate Features\n",
    "candidate_features = [\n",
    "    'Age', 'Gender_clean', 'self_employed', 'family_history',\n",
    "    'work_interfere', 'no_employees', 'remote_work', 'tech_company',\n",
    "    'benefits', 'care_options', 'wellness_program', 'seek_help', 'anonymity'\n",
    "]\n",
    "\n",
    "# Keep only features that actually exist in the dataset\n",
    "candidate_features = [c for c in candidate_features if c in df3.columns]\n",
    "print(\"Candidate features selected.\")\n",
    "\n",
    "\n",
    "# Build the Preprocessor\n",
    "# Separate numerical from categorical features\n",
    "num_features = [\n",
    "    c for c in candidate_features\n",
    "    if df3[c].dtype in ['int64', 'float64'] and c != 'treatment'\n",
    "]\n",
    "cat_features = [c for c in candidate_features if c not in num_features]\n",
    "\n",
    "print(f\"Numerical features: {num_features}\")\n",
    "print(f\"Categorical features: {cat_features}\")\n",
    "\n",
    "# Pipeline for numeric data: impute + scale\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical data:\n",
    "# - impute missing values\n",
    "# - convert everything to string\n",
    "# - one-hot encode\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('to_string', FunctionTransformer(lambda x: x.astype(str))),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine numerical + categorical pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, num_features),\n",
    "        ('cat', cat_pipeline, cat_features)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=0\n",
    ")\n",
    "\n",
    "print(\"Preprocessor created.\")\n",
    "\n",
    "\n",
    "# Define X and y\n",
    "target_col = 'treatment'\n",
    "print(f\"Shape before dropping NaNs in target: {df3.shape}\")\n",
    "\n",
    "# Remove rows with missing target labels\n",
    "df3 = df3.dropna(subset=[target_col])\n",
    "\n",
    "print(f\"Shape after dropping NaNs in target: {df3.shape}\")\n",
    "\n",
    "X = df3[candidate_features]\n",
    "y = df3[target_col]  # Already numeric (0/1)\n",
    "\n",
    "print(\"Target column 'y' is numeric.\")\n",
    "\n",
    "\n",
    "# Train/Test Split\n",
    "STATE = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\n",
    "\n",
    "# Build the Random Forest Pipeline\n",
    "# The pipeline performs preprocessing + model training in a single object\n",
    "pipe_rf = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('model', RandomForestClassifier(\n",
    "        random_state=STATE,\n",
    "        class_weight='balanced'   # important for imbalanced datasets\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"Random Forest pipeline created.\")\n",
    "print(\"--- All preparation steps completed. You can now run Cell 5. ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7134afbc-ce94-47e0-ba97-e07f1198f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: GridSearch cell\n",
    "# FORCE DATA CLEANUP\n",
    "print(\"--- FORCING DATA CLEANUP ---\")\n",
    "print(f\"Data type in y_train BEFORE fix: {y_train.dtype}\")\n",
    "print(\"Value counts in y_train BEFORE fix:\")\n",
    "print(y_train.value_counts(dropna=False)) \n",
    "\n",
    "# Convert \"Yes\"/\"No\" to 1/0 and drop any rows that fail conversion\n",
    "y_temp_numeric = pd.to_numeric(y_train.replace({'Yes': 1, 'No': 0}), errors='coerce')\n",
    "mask = y_temp_numeric.notna()\n",
    "\n",
    "# Filter X and y to include only valid rows\n",
    "X_train_clean = X_train[mask]\n",
    "y_train_clean = y_temp_numeric[mask]\n",
    "\n",
    "print(\"\\n--- DATA IS NOW CLEAN ---\")\n",
    "print(\"Value counts in y_train AFTER fix:\")\n",
    "print(y_train_clean.value_counts(dropna=False)) \n",
    "print(f\"Shape of X_train (clean): {X_train_clean.shape}\")\n",
    "print(f\"Shape of y_train (clean): {y_train_clean.shape}\")\n",
    "\n",
    "\n",
    "# -RUN GRIDSEARCH ON CLEAN DATA\n",
    "# Small parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators': [100, 150],     # Number of trees\n",
    "    'model__max_depth': [10, 15, None],    # Maximum depth per tree (None = unlimited)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=STATE)\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    pipe_rf,\n",
    "    param_grid_rf,\n",
    "    cv=cv,\n",
    "    scoring='f1',      # Optimize for the F1-score\n",
    "    n_jobs=4           # Use 4 CPU cores\n",
    ")\n",
    "\n",
    "print(\"\\nStarting GridSearch on CLEAN data... this may take a minute.\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the full RF pipeline (preprocessing + model) on the cleaned data\n",
    "grid_rf.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"GridSearch took {end_time - start_time:.2f} seconds.\")\n",
    "print(\"---\")\n",
    "\n",
    "# DISPLAY THE RESULTS\n",
    "print(f\"Best F1 score (in CV): {grid_rf.best_score_:.4f}\")     # Access .best_score_\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_rf.best_params_)                                   # Access .best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf49376-24aa-4900-bd21-e387e0d05f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluate on Test Set\n",
    "\n",
    "# Retrieve the best Random Forest model selected by GridSearch\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "# Make predictions on the (uncleaned) X_test.\n",
    "# The internal preprocessing pipeline inside best_rf will automatically clean X_test.\n",
    "# Therefore, y_pred_rf will already be numeric (1.0 / 0.0)\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# The variable y_test stored in memory is still \"dirty\" (contains 'Yes'/'No').\n",
    "# We must clean it using the EXACT same procedure we applied to y_train.\n",
    "print(f\"y_test values BEFORE fix: {y_test.value_counts(dropna=False).index[0:2]}...\")\n",
    "\n",
    "# Convert 'Yes'/'No' into 1/0.\n",
    "# Any other unexpected value (e.g., 'Don't Know') becomes NaN.\n",
    "y_test_numeric = pd.to_numeric(y_test.replace({'Yes': 1, 'No': 0}), errors='coerce')\n",
    "\n",
    "# Create a mask to keep only valid rows (those that are NOT NaN)\n",
    "mask = y_test_numeric.notna()\n",
    "\n",
    "# Apply the mask to BOTH y_test and the predictions.\n",
    "# This removes invalid rows and ensures perfect alignment.\n",
    "y_test_clean = y_test_numeric[mask]\n",
    "y_pred_rf_clean = y_pred_rf[mask]  \n",
    "\n",
    "print(f\"y_test values AFTER fix: {y_test_clean.value_counts(dropna=False).index[0:2]}...\")\n",
    "\n",
    "# Now evaluate using the cleaned and aligned test labels.\n",
    "print(\"\\nRandom Forest Test Classification Report:\")\n",
    "print(classification_report(y_test_clean, y_pred_rf_clean, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aafc11-9aa6-49e7-b60d-1c5220faaba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define Preprocessor (LR-Selected Features)\n",
    "\n",
    "# Define a NEW feature list\n",
    "# Based on your Cell 12 from Notebook 1, these were the features\n",
    "# that survived L1 regularization (i.e., coefficients ≠ 0).\n",
    "# I am excluding 'no_employees' and 'tech_company' since they didn't appear\n",
    "# in your top 10.\n",
    "lr_features = [\n",
    "    'Age',\n",
    "    'Gender_clean',\n",
    "    'family_history',\n",
    "    'work_interfere',\n",
    "    'benefits',\n",
    "    'care_options',\n",
    "    'anonymity'\n",
    "]\n",
    "\n",
    "print(f\"Running Experiment 2 with {len(lr_features)} selected features.\")\n",
    "\n",
    "# Split the selected features into numeric and categorical\n",
    "# We reuse the original 'num_features' and 'cat_features' lists.\n",
    "num_features_lr = [c for c in lr_features if c in num_features]\n",
    "cat_features_lr = [c for c in lr_features if c in cat_features]\n",
    "\n",
    "print(f\"LR Numeric features: {num_features_lr}\")\n",
    "print(f\"LR Categorical features: {cat_features_lr}\")\n",
    "\n",
    "# Build NEW pipelines (with *_lr names) ---\n",
    "# Same steps as before\n",
    "\n",
    "num_pipeline_lr = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline_lr = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('to_string', FunctionTransformer(lambda x: x.astype(str))),  \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Create the NEW ColumnTransformer\n",
    "preprocessor_lr = ColumnTransformer([\n",
    "    ('num', num_pipeline_lr, num_features_lr),\n",
    "    ('cat', cat_pipeline_lr, cat_features_lr)\n",
    "], remainder='drop', sparse_threshold=0)\n",
    "\n",
    "print(\"New 'preprocessor_lr' created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63cd3f-fd79-4c8a-86ac-19847a43a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: GridSearch for Random Forest using LR-selected features\n",
    "\n",
    "# Create a NEW Random Forest pipeline using the selected features from LR\n",
    "pipe_rf_lr = Pipeline([\n",
    "    ('pre', preprocessor_lr),  # Use the new preprocessor for LR-selected features\n",
    "    ('model', RandomForestClassifier(\n",
    "        random_state=STATE,\n",
    "        class_weight='balanced'   # Handle class imbalance\n",
    "    ))\n",
    "])\n",
    "print(\"New pipeline 'pipe_rf_lr' has been created.\")\n",
    "\n",
    "# Define the parameter grid (can reuse previous values)\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators': [100, 150],  # Number of trees\n",
    "    'model__max_depth': [10, 15, None], # Maximum depth of trees\n",
    "}\n",
    "\n",
    "# Set up the new GridSearch\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=STATE)\n",
    "grid_rf_lr = GridSearchCV(\n",
    "    pipe_rf_lr, \n",
    "    param_grid_rf, \n",
    "    cv=cv, \n",
    "    scoring='f1',   # Use F1 score to evaluate performance\n",
    "    n_jobs=4        # Use 4 CPU cores\n",
    ")\n",
    "\n",
    "print(\"\\nStarting GridSearch for Random Forest with LR-selected features...\")\n",
    "start_time_lr = time.time()\n",
    "\n",
    "# Train on the proper training data\n",
    "# X_train: DataFrame of training features (from Cell 4)\n",
    "# y_train_clean: cleaned target variable (from Cell 5)\n",
    "grid_rf_lr.fit(X_train, y_train_clean)\n",
    "\n",
    "end_time_lr = time.time()\n",
    "print(f\"GridSearch #2 finished in {end_time_lr - start_time_lr:.2f} seconds.\")\n",
    "print(\"---\")\n",
    "print(f\"Best F1 score (from CV) using LR features: {grid_rf_lr.best_score_:.4f}\")\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(grid_rf_lr.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a824b62-a2eb-46d4-820c-a4349eac820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Final Evaluation of Random Forest using LR-Selected Features\n",
    "\n",
    "print(\"--- Results for Random Forest Model with LR-Selected Features ---\")\n",
    "\n",
    "# Grab the best model from GridSearch\n",
    "best_rf_lr = grid_rf_lr.best_estimator_\n",
    "\n",
    "# Make predictions on the original test set\n",
    "y_pred_rf_lr = best_rf_lr.predict(X_test)\n",
    "\n",
    "# Clean the test target variable\n",
    "# Convert 'Yes'/'No' to numeric (1/0) and remove missing values\n",
    "y_test_numeric = pd.to_numeric(y_test.replace({'Yes': 1, 'No': 0}), errors='coerce')\n",
    "mask = y_test_numeric.notna()\n",
    "y_test_clean = y_test_numeric[mask]\n",
    "\n",
    "# Align predictions with the cleaned test data\n",
    "y_pred_rf_lr_clean = y_pred_rf_lr[mask]\n",
    "\n",
    "# Display a detailed classification report\n",
    "print(\"\\nRandom Forest Test Classification Report [LR Features]:\")\n",
    "print(classification_report(y_test_clean, y_pred_rf_lr_clean, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6706624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Graphical Overview of Hyperparameter Search (F1-Score vs. Max Depth)\n",
    "\n",
    "# Extract detailed GridSearch results\n",
    "# 'grid_rf' contains the results from the GridSearch\n",
    "results = pd.DataFrame(grid_rf.cv_results_)\n",
    "\n",
    "# Get the best hyperparameters from the winning model\n",
    "best_n_estimators = grid_rf.best_params_['model__n_estimators']\n",
    "best_depth = grid_rf.best_params_['model__max_depth']\n",
    "best_score = grid_rf.best_score_\n",
    "\n",
    "# Filter results to isolate the effect of max_depth\n",
    "# Only consider results with the optimal number of estimators\n",
    "depth_results = results[\n",
    "    results['param_model__n_estimators'] == best_n_estimators\n",
    "].sort_values(by='param_model__max_depth')\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Prepare X-axis labels, converting None to a readable string\n",
    "x_labels = depth_results['param_model__max_depth'].apply(\n",
    "    lambda x: 'None (Full)' if pd.isna(x) else int(x)\n",
    ")\n",
    "\n",
    "# Plot mean F1-Score from cross-validation\n",
    "plt.plot(\n",
    "    x_labels.astype(str), \n",
    "    depth_results['mean_test_score'], \n",
    "    marker='o', \n",
    "    linestyle='-', \n",
    "    color='darkgreen',\n",
    "    label='Mean F1-Score (5-Fold CV)'\n",
    ")\n",
    "\n",
    "# Highlight the best result\n",
    "best_depth_label = str(int(best_depth)) if not pd.isna(best_depth) else 'None (Full)'\n",
    "plt.scatter(\n",
    "    best_depth_label, \n",
    "    best_score, \n",
    "    color='red', \n",
    "    s=150, \n",
    "    label=f'Optimal Depth: {best_depth_label} (F1: {best_score:.4f})',\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Titles and styling\n",
    "plt.title('F1-Score vs. Maximum Tree Depth (Hyperparameter Search)')\n",
    "plt.xlabel('Maximum Tree Depth (max_depth)')\n",
    "plt.ylabel('Average F1-Score (Cross-Validation)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0eb28-5a11-441e-bdc2-d1db0e335d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Confusion Matrix (Final Evaluation)\n",
    "\n",
    "# Get the best estimator from GridSearch\n",
    "# Assume 'grid_rf' has already been run and 'best_estimator_' is available\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predicted = best_rf.predict(X_test)\n",
    "\n",
    "# Convert true labels to binary integers (0/1)\n",
    "# This step is crucial to avoid ValueErrors and ensure predictions and labels are compatible\n",
    "y_true_converted = y_test.replace({'No': 0, 'Yes': 1}).astype(int)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true_converted, y_predicted)\n",
    "\n",
    "# Set display labels for clarity\n",
    "labels_en = ['No Treatment (0)', 'Sought Treatment (1)']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_en)\n",
    "\n",
    "print(\"Confusion Matrix: Optimized Random Forest\")\n",
    "disp.plot(cmap=plt.cm.Blues, colorbar=False) \n",
    "disp.ax_.grid(False)  # Ensure a clean plot appearance\n",
    "plt.title('Random Forest - Confusion Matrix (Test Set)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b2da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: ROC Curve (Receiver Operating Characteristic) - Random Forest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score\n",
    "\n",
    "# Preparations\n",
    "# Assume 'grid_rf' has already been run and X_test is defined\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "# Convert y_test from strings ('Yes'/'No') to binary (0/1)\n",
    "# This ensures that RocCurveDisplay and roc_auc_score work correctly\n",
    "y_test_converted = y_test.replace({'No': 0, 'Yes': 1}).astype(int)\n",
    "\n",
    "# Create the plot axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the ROC curve for the optimized Random Forest\n",
    "RocCurveDisplay.from_estimator(\n",
    "    best_rf,              # The tuned RF model\n",
    "    X_test,\n",
    "    y_test_converted, \n",
    "    name='Random Forest (Tuned)',  # Legend label\n",
    "    ax=ax                        # Use the axis we created\n",
    ")\n",
    "\n",
    "# Add a reference \"chance\" line (random classifier)\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Chance (AUC = 0.50)')  # Dashed black line\n",
    "\n",
    "# Customize titles and labels\n",
    "ax.set_title('ROC Curve (Optimized Random Forest Model)')\n",
    "ax.set_xlabel('False Positive Rate (FPR)')\n",
    "ax.set_ylabel('True Positive Rate (TPR / Recall)')\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the AUC score separately\n",
    "# Extract predicted probabilities for the positive class (1)\n",
    "y_probs_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "auc_score_rf = roc_auc_score(y_test_converted, y_probs_rf)\n",
    "print(f\"Area Under the Curve (AUC Score): {auc_score_rf:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
